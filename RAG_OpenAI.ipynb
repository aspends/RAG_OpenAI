{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSOmsWqh21XM"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf langchain_openai langchain_community faiss-cpu --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "7eSt9SHK3SU6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"openai\")"
      ],
      "metadata": {
        "id": "312Wl1RA3oC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm=ChatOpenAI(model=\"gpt-4\")\n",
        "llm.invoke(\"Hi\")"
      ],
      "metadata": {
        "id": "vrMZUV8F3xZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "SH3674aG39kr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load and parse PDF\n",
        "loader = PyPDFLoader(\"\") #paste path to pdf\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "iru1kkZt4hg8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "sxwnIQgb5JI-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load to knowledge base\n",
        "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
        "\n",
        "faiss_index.save_local('document')"
      ],
      "metadata": {
        "id": "rIZPwgTy5qCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "JReFtoTs552E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vectors = FAISS.load_local('document', embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "#create a conversational retrieval chain\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm = OpenAI(),\n",
        "    retriever = vectors.as_retriever()\n",
        ")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "def rag(query):\n",
        "  response = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "  chat_history.append((query, response['answer']))\n",
        "\n",
        "  return response['answer'].strip()"
      ],
      "metadata": {
        "id": "gQ0DIO7B6Sef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag(\"\") #ask a question"
      ],
      "metadata": {
        "id": "RVRnMAFT6y8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}